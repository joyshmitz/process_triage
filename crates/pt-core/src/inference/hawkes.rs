//! Hawkes (self-exciting) point process layer for bursty event detection.
//!
//! This module implements a Hawkes process feature extractor for analyzing
//! bursty event streams (syscalls, I/O events, network events, etc.).
//!
//! # Model
//!
//! The Hawkes process models event times with intensity:
//! ```text
//! λ(t) = μ + Σ_{t_i < t} α · exp(-β(t - t_i))
//! ```
//!
//! Where:
//! - `μ` is the baseline (background) rate
//! - `α` is the excitation amplitude
//! - `β` is the decay rate
//!
//! The **branching ratio** `n = α/β` indicates burstiness:
//! - n < 1: subcritical (bursts die out)
//! - n ≈ 1: critical (long-lived cascades)
//! - n > 1: supercritical (explosive, unstable)
//!
//! # Features Extracted
//!
//! - Baseline rate `μ̂`
//! - Excitation amplitude `α̂`
//! - Decay rate `β̂`
//! - Branching ratio `n = α̂/β̂`
//! - Current intensity `λ̂(now)`
//! - Event count and time span
//!
//! # Example
//!
//! ```
//! use pt_core::inference::hawkes::{HawkesDetector, HawkesConfig};
//!
//! // Create detector with default config
//! let config = HawkesConfig::default();
//! let mut detector = HawkesDetector::new(config);
//!
//! // Add event timestamps (in seconds)
//! let events = vec![0.0, 0.1, 0.15, 0.18, 0.5, 1.0, 1.02, 1.05, 2.0];
//! let result = detector.fit(&events, 3.0); // window ends at t=3.0
//!
//! println!("Branching ratio: {:.3}", result.branching_ratio);
//! println!("Burst level: {:?}", result.burst_level);
//! ```

use serde::{Deserialize, Serialize};

/// Configuration for the Hawkes process detector.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HawkesConfig {
    /// Minimum baseline rate (prevents degenerate solutions).
    pub mu_min: f64,
    /// Maximum baseline rate.
    pub mu_max: f64,
    /// Initial guess for baseline rate.
    pub mu_init: f64,
    /// Initial guess for excitation amplitude.
    pub alpha_init: f64,
    /// Initial guess for decay rate.
    pub beta_init: f64,
    /// Maximum EM iterations.
    pub max_iters: usize,
    /// Convergence tolerance for log-likelihood.
    pub tol: f64,
    /// Minimum number of events required for fitting.
    pub min_events: usize,
    /// Maximum branching ratio cap (stability).
    pub max_branching_ratio: f64,
}

impl Default for HawkesConfig {
    fn default() -> Self {
        Self {
            mu_min: 1e-6,
            mu_max: 1e6,
            mu_init: 1.0,
            alpha_init: 0.5,
            beta_init: 1.0,
            max_iters: 100,
            tol: 1e-6,
            min_events: 3,
            max_branching_ratio: 0.99, // Keep subcritical for stability
        }
    }
}

/// Burst intensity level classification.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub enum BurstLevel {
    /// Very low burst activity (n < 0.1).
    VeryLow,
    /// Low burst activity (0.1 <= n < 0.3).
    Low,
    /// Moderate burst activity (0.3 <= n < 0.5).
    Moderate,
    /// High burst activity (0.5 <= n < 0.7).
    High,
    /// Very high burst activity (n >= 0.7).
    VeryHigh,
}

impl std::fmt::Display for BurstLevel {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            BurstLevel::VeryLow => write!(f, "very_low"),
            BurstLevel::Low => write!(f, "low"),
            BurstLevel::Moderate => write!(f, "moderate"),
            BurstLevel::High => write!(f, "high"),
            BurstLevel::VeryHigh => write!(f, "very_high"),
        }
    }
}

/// Result of Hawkes process fitting.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HawkesResult {
    /// Estimated baseline rate (events per unit time).
    pub baseline_rate: f64,
    /// Estimated excitation amplitude.
    pub excitation_alpha: f64,
    /// Estimated decay rate.
    pub decay_beta: f64,
    /// Branching ratio (α/β) - measure of burstiness.
    pub branching_ratio: f64,
    /// Current intensity at window end.
    pub current_intensity: f64,
    /// Classified burst level.
    pub burst_level: BurstLevel,
    /// Log-likelihood of the fitted model.
    pub log_likelihood: f64,
    /// Number of events in the window.
    pub event_count: usize,
    /// Time span of the window (seconds).
    pub time_span: f64,
    /// Average event rate over the window.
    pub average_rate: f64,
    /// Number of EM iterations used.
    pub iterations: usize,
    /// Whether fitting converged.
    pub converged: bool,
}

impl HawkesResult {
    /// Create a result for insufficient data.
    pub fn insufficient_data(event_count: usize, time_span: f64) -> Self {
        let average_rate = if time_span > 0.0 {
            event_count as f64 / time_span
        } else {
            0.0
        };

        Self {
            baseline_rate: average_rate,
            excitation_alpha: 0.0,
            decay_beta: 1.0,
            branching_ratio: 0.0,
            current_intensity: average_rate,
            burst_level: BurstLevel::VeryLow,
            log_likelihood: f64::NEG_INFINITY,
            event_count,
            time_span,
            average_rate,
            iterations: 0,
            converged: false,
        }
    }

    /// Classify branching ratio into burst level.
    fn classify_burst(branching_ratio: f64) -> BurstLevel {
        if branching_ratio < 0.1 {
            BurstLevel::VeryLow
        } else if branching_ratio < 0.3 {
            BurstLevel::Low
        } else if branching_ratio < 0.5 {
            BurstLevel::Moderate
        } else if branching_ratio < 0.7 {
            BurstLevel::High
        } else {
            BurstLevel::VeryHigh
        }
    }
}

/// Hawkes process detector with exponential kernel.
#[derive(Debug, Clone)]
pub struct HawkesDetector {
    config: HawkesConfig,
}

impl HawkesDetector {
    /// Create a new detector with the given configuration.
    pub fn new(config: HawkesConfig) -> Self {
        Self { config }
    }

    /// Create a detector with default configuration.
    pub fn with_defaults() -> Self {
        Self::new(HawkesConfig::default())
    }

    /// Fit the Hawkes process to event timestamps.
    ///
    /// # Arguments
    /// * `events` - Sorted event timestamps (in seconds from some reference)
    /// * `window_end` - End time of the observation window
    ///
    /// # Returns
    /// Fitted Hawkes parameters and summary statistics.
    pub fn fit(&self, events_slice: &[f64], window_end: f64) -> HawkesResult {
        // Ensure events are sorted for causality
        let mut events = events_slice.to_vec();
        events.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        let events = events; // Shadow with sorted Vec

        let n = events.len();

        // Compute time span
        let time_span = if n > 0 {
            window_end - events[0].min(window_end)
        } else {
            window_end
        };

        // Check minimum events
        if n < self.config.min_events {
            return HawkesResult::insufficient_data(n, time_span);
        }

        // Initialize parameters
        // Simple initialization based on data
        let empirical_rate = n as f64 / time_span.max(1e-10);
        let mut mu = empirical_rate
            .max(self.config.mu_min)
            .min(self.config.mu_max);
        let mut alpha = self.config.alpha_init;
        let mut beta = self.config.beta_init;

        // Precompute inter-arrival times
        let mut prev_ll = f64::NEG_INFINITY;
        let mut converged = false;
        let mut iterations = 0;

        // EM algorithm for Hawkes process with exponential kernel
        for iter in 0..self.config.max_iters {
            iterations = iter + 1;

            // E-step: compute responsibilities
            // For each event, compute probability it was triggered by background vs excitation
            let (responsibilities, intensities) = self.e_step(&events, mu, alpha, beta);

            // M-step: update parameters
            let (new_mu, new_alpha, new_beta) =
                self.m_step(&events, &responsibilities, time_span, alpha, beta);

            // Apply constraints
            mu = new_mu.max(self.config.mu_min).min(self.config.mu_max);
            alpha = new_alpha.max(0.0);
            beta = new_beta.max(0.01);

            // Enforce branching ratio constraint
            let n_ratio = alpha / beta;
            if n_ratio > self.config.max_branching_ratio {
                alpha = self.config.max_branching_ratio * beta;
            }

            // Compute log-likelihood
            let ll = self.log_likelihood(&events, window_end, mu, alpha, beta, &intensities);

            // Check convergence
            if (ll - prev_ll).abs() < self.config.tol {
                converged = true;
                break;
            }
            prev_ll = ll;
        }

        // Compute final intensity at window end
        let current_intensity = self.intensity_at(&events, window_end, mu, alpha, beta);

        // Compute final log-likelihood
        let (_, intensities) = self.e_step(&events, mu, alpha, beta);
        let log_likelihood =
            self.log_likelihood(&events, window_end, mu, alpha, beta, &intensities);

        let branching_ratio = if beta > 0.0 { alpha / beta } else { 0.0 };

        HawkesResult {
            baseline_rate: mu,
            excitation_alpha: alpha,
            decay_beta: beta,
            branching_ratio,
            current_intensity,
            burst_level: HawkesResult::classify_burst(branching_ratio),
            log_likelihood,
            event_count: n,
            time_span,
            average_rate: empirical_rate,
            iterations,
            converged,
        }
    }

    /// E-step: compute responsibilities for each event.
    ///
    /// Returns (responsibilities, intensities) where:
    /// - responsibilities[i] = P(event i was background) for each event
    /// - intensities[i] = λ(t_i) at each event time
    fn e_step(&self, events: &[f64], mu: f64, alpha: f64, beta: f64) -> (Vec<f64>, Vec<f64>) {
        let n = events.len();
        let mut responsibilities = vec![0.0; n];
        let mut intensities = vec![0.0; n];

        // Recursive computation of intensity at each event
        // A(t_i) = Σ_{j<i} exp(-β(t_i - t_j)) can be computed recursively:
        // A(t_i) = (A(t_{i-1}) + 1) * exp(-β(t_i - t_{i-1}))
        let mut a_recursive = 0.0; // Σ exp(-β(t_i - t_j)) for j < i

        for i in 0..n {
            if i > 0 {
                let dt = events[i] - events[i - 1];
                a_recursive = (a_recursive + 1.0) * (-beta * dt).exp();
            }

            // Intensity at event i (just before)
            let lambda_i = mu + alpha * a_recursive;
            intensities[i] = lambda_i.max(1e-10);

            // Responsibility: P(background | event i) = μ / λ(t_i)
            responsibilities[i] = mu / intensities[i];
        }

        (responsibilities, intensities)
    }

    /// M-step: update parameters given responsibilities.
    fn m_step(
        &self,
        events: &[f64],
        responsibilities: &[f64],
        time_span: f64,
        _prev_alpha: f64,
        prev_beta: f64,
    ) -> (f64, f64, f64) {
        let n = events.len();
        if n == 0 || time_span <= 0.0 {
            return (self.config.mu_init, 0.0, prev_beta);
        }

        // Update mu: sum of responsibilities / time span
        let sum_p = responsibilities.iter().sum::<f64>();
        let new_mu = sum_p / time_span;

        // Update alpha and beta using moment matching / EM updates
        // Expected number of offspring events
        let sum_q = n as f64 - sum_p; // Sum of (1 - p_i) = excitation probability

        // For beta, we use the weighted inter-arrival times
        // This is a simplified update based on the expected decay
        let mut weighted_sum = 0.0;
        let mut weight_total = 0.0;

        for i in 1..n {
            let dt = events[i] - events[i - 1];
            let q_i = 1.0 - responsibilities[i]; // Probability event i was triggered

            if q_i > 0.01 && dt > 0.0 {
                // Weight by trigger probability
                weighted_sum += q_i * dt;
                weight_total += q_i;
            }
        }

        // New beta: inverse of expected time to trigger
        let new_beta = if weight_total > 0.0 && weighted_sum > 0.0 {
            weight_total / weighted_sum
        } else {
            prev_beta
        };

        // New alpha: based on average offspring per event
        let avg_offspring = sum_q / n.max(1) as f64;
        let new_alpha = avg_offspring * new_beta;

        (new_mu, new_alpha, new_beta)
    }

    /// Compute intensity at a given time.
    fn intensity_at(&self, events: &[f64], t: f64, mu: f64, alpha: f64, beta: f64) -> f64 {
        let mut intensity = mu;
        for &t_i in events {
            if t_i < t {
                intensity += alpha * (-beta * (t - t_i)).exp();
            }
        }
        intensity
    }

    /// Compute log-likelihood of the model.
    fn log_likelihood(
        &self,
        events: &[f64],
        window_end: f64,
        mu: f64,
        alpha: f64,
        beta: f64,
        intensities: &[f64],
    ) -> f64 {
        if events.is_empty() {
            return 0.0;
        }

        let window_start = events[0];

        // Sum of log intensities at events
        let log_intensity_sum: f64 = intensities.iter().map(|&l| l.ln()).sum();

        // Integral of intensity over window
        // ∫ λ(t) dt = μ * T + (α/β) * Σ (1 - exp(-β(T - t_i)))
        let t_span = window_end - window_start;
        let mut integral = mu * t_span;

        if beta > 0.0 {
            for &t_i in events {
                if t_i < window_end {
                    integral += (alpha / beta) * (1.0 - (-beta * (window_end - t_i)).exp());
                }
            }
        }

        log_intensity_sum - integral
    }

    /// Fit Hawkes process from raw timestamps.
    ///
    /// # Arguments
    /// * `timestamps` - Unsorted timestamps (will be sorted internally)
    /// * `window_start` - Start of observation window
    /// * `window_end` - End of observation window
    pub fn fit_raw(&self, timestamps: &[f64], window_start: f64, window_end: f64) -> HawkesResult {
        // Filter and sort events within window
        let mut events: Vec<f64> = timestamps
            .iter()
            .copied()
            .filter(|&t| t >= window_start && t < window_end)
            .collect();
        events.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

        // Shift to relative time
        let shifted: Vec<f64> = events.iter().map(|&t| t - window_start).collect();
        let duration = window_end - window_start;

        self.fit(&shifted, duration)
    }
}

impl Default for HawkesDetector {
    fn default() -> Self {
        Self::with_defaults()
    }
}

/// Evidence term for integration with the decision core.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HawkesEvidence {
    /// The Hawkes fitting result.
    pub result: HawkesResult,
    /// Log-odds contribution (positive supports useful_bad).
    pub log_odds: f64,
    /// Feature glyph for display.
    pub glyph: char,
    /// Short description.
    pub description: String,
}

impl HawkesEvidence {
    /// Create evidence from a Hawkes result.
    ///
    /// High branching ratio suggests tight loop / runaway behavior.
    pub fn from_result(result: HawkesResult, stream_name: &str) -> Self {
        // Map branching ratio to log-odds
        // High branching → supports useful_bad (tight loop, runaway)
        // Low branching → neutral or supports useful
        let log_odds = if result.branching_ratio > 0.7 {
            // Very high burst activity - likely tight loop
            1.5
        } else if result.branching_ratio > 0.5 {
            // High burst activity
            0.8
        } else if result.branching_ratio > 0.3 {
            // Moderate - slightly suspicious
            0.3
        } else if result.branching_ratio < 0.1 {
            // Very low - steady, supports useful
            -0.3
        } else {
            // Low/normal
            0.0
        };

        // Glyph based on burst level
        let glyph = match result.burst_level {
            BurstLevel::VeryLow => '·',
            BurstLevel::Low => '○',
            BurstLevel::Moderate => '◐',
            BurstLevel::High => '◑',
            BurstLevel::VeryHigh => '●',
        };

        let description = format!(
            "{} burst activity: branching={:.2}, rate={:.1}/s",
            stream_name, result.branching_ratio, result.average_rate
        );

        Self {
            result,
            log_odds,
            glyph,
            description,
        }
    }
}

/// Summary for multivariate Hawkes (cross-excitation).
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CrossExcitationSummary {
    /// Stream name pairs with cross-excitation.
    pub pairs: Vec<(String, String, f64)>,
    /// Dominant source stream (most excites others).
    pub dominant_source: Option<String>,
    /// Dominant sink stream (most excited by others).
    pub dominant_sink: Option<String>,
}

/// Configuration for cross-excitation summary.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CrossExcitationConfig {
    /// Window size for considering triggered events (seconds).
    pub window_s: f64,
    /// Minimum events required per stream to compute scores.
    pub min_events: usize,
}

impl Default for CrossExcitationConfig {
    fn default() -> Self {
        Self {
            window_s: 1.0,
            min_events: 3,
        }
    }
}

/// Summarize cross-excitation between multiple event streams.
pub fn summarize_cross_excitation(
    streams: &[(String, Vec<f64>)],
    config: &CrossExcitationConfig,
) -> CrossExcitationSummary {
    if streams.is_empty() {
        return CrossExcitationSummary {
            pairs: Vec::new(),
            dominant_source: None,
            dominant_sink: None,
        };
    }

    let mut pairs = Vec::new();
    let mut source_scores: Vec<(String, f64)> = Vec::new();
    let mut sink_scores: Vec<(String, f64)> = Vec::new();

    for (i, (name_i, events_i)) in streams.iter().enumerate() {
        if events_i.len() < config.min_events {
            source_scores.push((name_i.clone(), 0.0));
            continue;
        }
        let mut source_total = 0.0;
        let mut sorted_i = events_i.clone();
        sorted_i.sort_by(|a, b| a.total_cmp(b));

        for (j, (name_j, events_j)) in streams.iter().enumerate() {
            if i == j || events_j.len() < config.min_events {
                continue;
            }
            let mut sorted_j = events_j.clone();
            sorted_j.sort_by(|a, b| a.total_cmp(b));

            let score = cross_excitation_score(&sorted_i, &sorted_j, config.window_s);
            pairs.push((name_i.clone(), name_j.clone(), score));
            source_total += score;
        }
        source_scores.push((name_i.clone(), source_total));
    }

    for (name_j, events_j) in streams.iter() {
        if events_j.len() < config.min_events {
            sink_scores.push((name_j.clone(), 0.0));
            continue;
        }
        let mut sink_total = 0.0;
        for (name_i, _events_i) in streams.iter() {
            if name_i == name_j {
                continue;
            }
            if let Some((_, _, score)) = pairs
                .iter()
                .find(|(src, dst, _)| src == name_i && dst == name_j)
            {
                sink_total += *score;
            }
        }
        sink_scores.push((name_j.clone(), sink_total));
    }

    let dominant_source = source_scores
        .iter()
        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal))
        .and_then(|(name, score)| {
            if *score > 0.0 {
                Some(name.clone())
            } else {
                None
            }
        });

    let dominant_sink = sink_scores
        .iter()
        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal))
        .and_then(|(name, score)| {
            if *score > 0.0 {
                Some(name.clone())
            } else {
                None
            }
        });

    CrossExcitationSummary {
        pairs,
        dominant_source,
        dominant_sink,
    }
}

fn cross_excitation_score(source: &[f64], target: &[f64], window_s: f64) -> f64 {
    if source.is_empty() || target.is_empty() || window_s <= 0.0 {
        return 0.0;
    }
    let mut count = 0usize;
    let mut j = 0usize;
    for &t in source {
        while j < target.len() && target[j] <= t {
            j += 1;
        }
        let mut k = j;
        while k < target.len() && target[k] <= t + window_s {
            count += 1;
            k += 1;
        }
    }
    count as f64 / source.len() as f64
}

#[cfg(test)]
mod tests {
    use super::*;

    fn approx_eq(a: f64, b: f64, tol: f64) -> bool {
        (a - b).abs() <= tol
    }

    #[test]
    fn test_hawkes_config_default() {
        let config = HawkesConfig::default();
        assert!(config.mu_min > 0.0);
        assert!(config.max_branching_ratio < 1.0);
    }

    #[test]
    fn test_hawkes_insufficient_data() {
        let detector = HawkesDetector::with_defaults();
        let events = vec![0.0, 0.5]; // Only 2 events, below threshold

        let result = detector.fit(&events, 1.0);

        assert_eq!(result.event_count, 2);
        assert!(!result.converged);
    }

    #[test]
    fn test_hawkes_poisson_stream() {
        // Regular (Poisson-like) events with some noise
        let detector = HawkesDetector::with_defaults();
        // Add slight jitter to make it more Poisson-like (not perfectly regular)
        let events: Vec<f64> = (0..20)
            .map(|i| i as f64 * 0.5 + (i % 3) as f64 * 0.05)
            .collect();

        let result = detector.fit(&events, 10.0);

        // Detector should produce valid output for regular stream
        // Note: simplified EM may not perfectly distinguish Poisson from Hawkes
        // but should stay within stable bounds
        assert!(
            result.branching_ratio <= detector.config.max_branching_ratio,
            "Branching ratio {} should be capped at {}",
            result.branching_ratio,
            detector.config.max_branching_ratio
        );
        assert!(result.converged || result.iterations > 0);
        assert!(result.baseline_rate > 0.0);
    }

    #[test]
    fn test_hawkes_bursty_stream() {
        // Bursty events - clustered arrivals
        let detector = HawkesDetector::with_defaults();
        let mut events = Vec::new();

        // Create bursts: events clustered at 0, 2, 4, 6, 8 seconds
        for burst in 0..5 {
            let base = burst as f64 * 2.0;
            events.push(base);
            events.push(base + 0.01);
            events.push(base + 0.03);
            events.push(base + 0.05);
        }

        let result = detector.fit(&events, 10.0);

        // Bursty stream should have higher branching ratio
        // Note: may not be extremely high due to EM initialization
        assert!(result.event_count == 20);
        assert!(result.converged || result.iterations > 5);
    }

    fn find_pair_score(pairs: &[(String, String, f64)], src: &str, dst: &str) -> Option<f64> {
        pairs
            .iter()
            .find(|(s, d, _)| s == src && d == dst)
            .map(|(_, _, score)| *score)
    }

    #[test]
    fn test_cross_excitation_directional_trigger() {
        let streams = vec![
            ("cpu".to_string(), vec![0.0, 1.0, 2.0]),
            ("io".to_string(), vec![0.1, 1.1, 2.1]),
            ("net".to_string(), vec![0.5, 1.5, 2.5]),
        ];
        let config = CrossExcitationConfig {
            window_s: 0.2,
            min_events: 3,
        };

        let summary = summarize_cross_excitation(&streams, &config);

        let cpu_to_io = find_pair_score(&summary.pairs, "cpu", "io").unwrap_or(0.0);
        let io_to_cpu = find_pair_score(&summary.pairs, "io", "cpu").unwrap_or(0.0);
        let cpu_to_net = find_pair_score(&summary.pairs, "cpu", "net").unwrap_or(0.0);

        assert!(approx_eq(cpu_to_io, 1.0, 1e-9));
        assert!(approx_eq(io_to_cpu, 0.0, 1e-9));
        assert!(approx_eq(cpu_to_net, 0.0, 1e-9));
        assert_eq!(summary.dominant_source.as_deref(), Some("cpu"));
        assert_eq!(summary.dominant_sink.as_deref(), Some("io"));
    }

    #[test]
    fn test_cross_excitation_min_events_gate() {
        let streams = vec![
            ("cpu".to_string(), vec![0.0, 1.0, 2.0]),
            ("io".to_string(), vec![0.1, 1.1]),
        ];
        let config = CrossExcitationConfig {
            window_s: 0.2,
            min_events: 3,
        };

        let summary = summarize_cross_excitation(&streams, &config);

        assert!(summary.pairs.is_empty());
        assert!(summary.dominant_source.is_none());
        assert!(summary.dominant_sink.is_none());
    }

    #[test]
    fn test_hawkes_intensity_at() {
        let detector = HawkesDetector::with_defaults();
        let events = vec![0.0, 0.1, 0.2];
        let mu = 1.0;
        let alpha = 0.5;
        let beta = 2.0;

        // At t=0, only baseline
        let intensity_0 = detector.intensity_at(&events, 0.0, mu, alpha, beta);
        assert!(approx_eq(intensity_0, mu, 1e-10));

        // At t > last event, should have decaying contribution
        let intensity_1 = detector.intensity_at(&events, 1.0, mu, alpha, beta);
        assert!(intensity_1 > mu); // Still some excitation
        assert!(intensity_1 < mu + 3.0 * alpha); // Decayed from peak
    }

    #[test]
    fn test_hawkes_fit_raw() {
        let detector = HawkesDetector::with_defaults();
        let timestamps = vec![100.0, 100.5, 101.0, 101.5, 102.0, 102.5];

        let result = detector.fit_raw(&timestamps, 100.0, 103.0);

        assert_eq!(result.event_count, 6);
        assert!(approx_eq(result.time_span, 3.0, 0.01));
    }

    #[test]
    fn test_burst_level_classification() {
        assert_eq!(HawkesResult::classify_burst(0.05), BurstLevel::VeryLow);
        assert_eq!(HawkesResult::classify_burst(0.2), BurstLevel::Low);
        assert_eq!(HawkesResult::classify_burst(0.4), BurstLevel::Moderate);
        assert_eq!(HawkesResult::classify_burst(0.6), BurstLevel::High);
        assert_eq!(HawkesResult::classify_burst(0.8), BurstLevel::VeryHigh);
    }

    #[test]
    fn test_hawkes_evidence() {
        let detector = HawkesDetector::with_defaults();
        let events: Vec<f64> = (0..10).map(|i| i as f64 * 0.1).collect();

        let result = detector.fit(&events, 1.0);
        let evidence = HawkesEvidence::from_result(result, "syscall");

        assert!(evidence.log_odds.is_finite());
        assert!(evidence.description.contains("syscall"));
    }

    #[test]
    fn test_hawkes_single_burst() {
        let detector = HawkesDetector::with_defaults();
        // All events in a tight burst
        let events = vec![0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09];

        let result = detector.fit(&events, 1.0);

        // Should detect high excitation from tight clustering
        assert!(result.event_count == 10);
        // Average rate is 10 events / 1 second
        assert!(result.average_rate > 5.0);
    }

    #[test]
    fn test_hawkes_empty_events() {
        let detector = HawkesDetector::with_defaults();
        let events: Vec<f64> = vec![];

        let result = detector.fit(&events, 1.0);

        assert_eq!(result.event_count, 0);
        assert!(!result.converged);
    }

    #[test]
    fn test_hawkes_branching_ratio_capped() {
        let detector = HawkesDetector::with_defaults();

        // Extreme burst that might cause supercritical estimate
        let mut events = vec![0.0];
        for _ in 0..50 {
            let last = *events.last().unwrap();
            events.push(last + 0.001); // Very tight clustering
        }

        let result = detector.fit(&events, 1.0);

        // Branching ratio should be capped below 1
        assert!(
            result.branching_ratio <= detector.config.max_branching_ratio,
            "Branching ratio {} exceeds max {}",
            result.branching_ratio,
            detector.config.max_branching_ratio
        );
    }

    #[test]
    fn test_burst_level_display() {
        assert_eq!(BurstLevel::VeryLow.to_string(), "very_low");
        assert_eq!(BurstLevel::High.to_string(), "high");
    }

    #[test]
    fn test_e_step_intensities_positive() {
        let detector = HawkesDetector::with_defaults();
        let events = vec![0.0, 0.5, 1.0, 1.5, 2.0];

        let (responsibilities, intensities) = detector.e_step(&events, 0.5, 0.3, 1.0);

        // All intensities should be positive
        for &intensity in &intensities {
            assert!(
                intensity > 0.0,
                "Intensity should be positive: {}",
                intensity
            );
        }

        // Responsibilities should be in [0, 1]
        for &p in &responsibilities {
            assert!(p >= 0.0 && p <= 1.0, "Responsibility out of range: {}", p);
        }
    }
}
